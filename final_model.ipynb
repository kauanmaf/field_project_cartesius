{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from classic_patterns import classic_ml_data\n",
    "from indicadores import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "returns_series\n",
      "0      -0.002515\n",
      "1      -0.081723\n",
      "2      -0.134312\n",
      "3      -0.175470\n",
      "4      -0.019431\n",
      "          ...   \n",
      "3555    0.061436\n",
      "3556    0.009204\n",
      "3557    0.030082\n",
      "3558   -0.007300\n",
      "3559    0.009767\n",
      "Length: 3560, dtype: float64\n",
      "returns_series\n",
      "0            NaN\n",
      "1       0.056009\n",
      "2       0.063704\n",
      "3       0.068316\n",
      "4       0.079537\n",
      "          ...   \n",
      "3555    0.046376\n",
      "3556    0.038243\n",
      "3557    0.032097\n",
      "3558    0.030072\n",
      "3559    0.024568\n",
      "Length: 3560, dtype: float64\n",
      "[nan, 0.05600866566138478, 0.06370374937981206, 0.0683157993062677, 0.07953702477780306, 0.11950940410898792, 0.09549885580369279, 0.07687153965758123, 0.07453256179382457, 0.07340546021232042]\n",
      "returns_series[:10]\n",
      "[0.051248915737722466, 0.044683419283526246, 0.07128063674707072, 0.058206728659875334, 0.05167097695847133, 0.0421810724868715, 0.03762627047562024, 0.032900063218733865, 0.02767061092564653]\n",
      "returns_series[11:20]\n",
      "[0.021342047337842753, 0.03557470353318286, 0.03567833504873975, 0.040650824174106634, 0.04012125964815533, 0.036998500016016046, 0.032305427464305536, 0.027619984500003626, 0.03162447700132924]\n",
      "returns_series[21:30]\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 0.]]\n"
     ]
    }
   ],
   "source": [
    "import labeling as lb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Juntando os dados\n",
    "Pegando os dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertendo para numpy arrays, caso ainda não estejam\n",
    "ml_tsla_data = np.array(classic_ml_data)  \n",
    "label_tsla_data = np.array(lb.label_tsla_data).ravel()\n",
    "\n",
    "# Divide os dados em conjuntos de treinamento e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(ml_tsla_data, label_tsla_data, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fazendo a Rede Neural"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlp(data, hidden_layers=(100, 100, 100), activation='logistic', \n",
    "        solver='adam', max_iter=500, random_state=42):\n",
    "    \"\"\"\n",
    "    Treina um modelo de rede neural MLP e retorna as previsões e o relatório de classificação.\n",
    "\n",
    "    Parâmetros:\n",
    "    - data: DataFrame contendo os dados de entrada.\n",
    "    - hidden_layers: Tupla com o tamanho das camadas ocultas.\n",
    "    - activation: Função de ativação a ser usada.\n",
    "    - solver: Algoritmo de otimização a ser usado.\n",
    "    - max_iter: Número máximo de iterações.\n",
    "    - random_state: Semente para a geração de números aleatórios.\n",
    "\n",
    "    Retorna:\n",
    "    - y_pred_mlp: Previsões das classes no conjunto de teste.\n",
    "    - report: Relatório de classificação.\n",
    "    \"\"\"\n",
    "    \n",
    "    # 1. Agregar os indicadores\n",
    "    indicators_df = agg_indicators(data)\n",
    "\n",
    "    # 2. Normalizar os indicadores\n",
    "    normalized_data = normalize_indicators(indicators_df)\n",
    "\n",
    "    # 3. Separar as variáveis independentes (X) e dependentes (y)\n",
    "    X = normalized_data.drop(columns=['Adj Close'])  # Variáveis independentes\n",
    "    y = normalized_data['Adj Close']  # Variável dependente\n",
    "\n",
    "    # 4. Dividir os dados em conjuntos de treinamento e teste\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=random_state)\n",
    "\n",
    "    # 5. Define a rede neural com múltiplas camadas\n",
    "    mlp = MLPClassifier(hidden_layer_sizes=hidden_layers, activation=activation,\n",
    "                        solver=solver, max_iter=max_iter, random_state=random_state)\n",
    "\n",
    "    # 6. Treina a rede neural\n",
    "    mlp.fit(X_train, y_train)\n",
    "\n",
    "    # 7. Faz previsões de classe\n",
    "    y_pred_mlp = mlp.predict(X_test)\n",
    "\n",
    "    # 8. Exibe o relatório de classificação para o MLP\n",
    "    report = classification_report(y_test, y_pred_mlp)\n",
    "    print(report)\n",
    "\n",
    "    return y_pred_mlp, report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fazendo o Modelo Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.00      0.00      0.00         9\n",
      "         0.0       0.47      0.10      0.17       357\n",
      "         1.0       0.48      0.88      0.63       347\n",
      "\n",
      "    accuracy                           0.48       713\n",
      "   macro avg       0.32      0.33      0.27       713\n",
      "weighted avg       0.47      0.48      0.39       713\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Léo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Léo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Léo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "def random_forest(data, target_column, n_estimators=100, max_depth=None, random_state=42):\n",
    "    \"\"\"\n",
    "    Treina um modelo de Random Forest e retorna as previsões e o relatório de classificação.\n",
    "\n",
    "    Parâmetros:\n",
    "    - data: DataFrame com as features e a variável alvo.\n",
    "    - target_column: Nome da coluna alvo no DataFrame.\n",
    "    - n_estimators: Número de árvores na floresta.\n",
    "    - max_depth: Profundidade máxima das árvores (None para ilimitado).\n",
    "    - random_state: Semente para a geração de números aleatórios.\n",
    "\n",
    "    Retorna:\n",
    "    - y_pred_rf: Previsões das classes no conjunto de teste.\n",
    "    - report: Relatório de classificação.\n",
    "    \"\"\"\n",
    "    \n",
    "    # 1. Aplica as funções de pré-processamento\n",
    "    data = agg_indicators(data)  # Ajuste conforme necessário\n",
    "    normalized_data = normalize_indicators(data)  # Ajuste conforme necessário\n",
    "\n",
    "    # 2. Define X e y\n",
    "    X = normalized_data.drop(columns=[target_column])  # Variáveis independentes\n",
    "    y = normalized_data[target_column]  # Variável dependente\n",
    "\n",
    "    # 3. Divide os dados em conjuntos de treinamento e teste\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=random_state)\n",
    "\n",
    "    # 4. Define o modelo Random Forest\n",
    "    rf = RandomForestClassifier(n_estimators=n_estimators, max_depth=max_depth, \n",
    "                                 random_state=random_state)\n",
    "\n",
    "    # 5. Treina o modelo Random Forest\n",
    "    rf.fit(X_train, y_train)\n",
    "\n",
    "    # 6. Faz previsões de classe\n",
    "    y_pred_rf = rf.predict(X_test)\n",
    "\n",
    "    # 7. Exibe o relatório de classificação para o Random Forest\n",
    "    report = classification_report(y_test, y_pred_rf)\n",
    "    print(report)\n",
    "\n",
    "    return y_pred_rf, report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fazendo o Modelo Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.00      0.00      0.00         9\n",
      "         0.0       0.45      0.07      0.12       357\n",
      "         1.0       0.48      0.92      0.63       347\n",
      "\n",
      "    accuracy                           0.48       713\n",
      "   macro avg       0.31      0.33      0.25       713\n",
      "weighted avg       0.46      0.48      0.37       713\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Léo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Léo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Léo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "def gradient_boosting(data, target_column, random_state=42):\n",
    "    \"\"\"\n",
    "    Treina um modelo de Gradient Boosting e retorna as previsões e o relatório de classificação.\n",
    "\n",
    "    Parâmetros:\n",
    "    - data: DataFrame com as features e a variável alvo.\n",
    "    - target_column: Nome da coluna alvo no DataFrame.\n",
    "    - random_state: Semente para a geração de números aleatórios.\n",
    "\n",
    "    Retorna:\n",
    "    - y_pred_gb: Previsões das classes no conjunto de teste.\n",
    "    - report: Relatório de classificação.\n",
    "    \"\"\"\n",
    "    \n",
    "    # 1. Aplica as funções de pré-processamento\n",
    "    data = agg_indicators(data)  # Ajuste conforme necessário\n",
    "    normalized_data = normalize_indicators(data)  # Ajuste conforme necessário\n",
    "\n",
    "    # 2. Define X e y\n",
    "    X = normalized_data.drop(columns=[target_column])  # Variáveis independentes\n",
    "    y = normalized_data[target_column]  # Variável dependente\n",
    "\n",
    "    # 3. Divide os dados em conjuntos de treinamento e teste\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=random_state)\n",
    "\n",
    "    # 4. Define o modelo Gradient Boosting\n",
    "    gb_model = GradientBoostingClassifier(random_state=random_state)\n",
    "\n",
    "    # 5. Treina o modelo Gradient Boosting\n",
    "    gb_model.fit(X_train, y_train)\n",
    "\n",
    "    # 6. Faz previsões de classe\n",
    "    y_pred_gb = gb_model.predict(X_test)\n",
    "\n",
    "    # 7. Exibe o relatório de classificação para o Gradient Boosting\n",
    "    report = classification_report(y_test, y_pred_gb)\n",
    "    print(report)\n",
    "\n",
    "    return y_pred_gb, report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2.52374159e-03 1.96985076e-01 8.00491182e-01]\n",
      " [1.19982149e-02 4.84471646e-01 5.03530139e-01]\n",
      " [1.41937404e-03 4.40327581e-01 5.58253045e-01]\n",
      " ...\n",
      " [1.41937404e-03 4.40327581e-01 5.58253045e-01]\n",
      " [7.99688317e-04 4.84704645e-01 5.14495666e-01]\n",
      " [4.63652258e-03 4.78172482e-01 5.17190995e-01]]\n"
     ]
    }
   ],
   "source": [
    "print(y_pred_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  precision    recall  f1-score   support\n",
      "\n",
      "Desfazer Posição       0.01      0.78      0.02         9\n",
      "          Compra       0.00      0.00      0.00       357\n",
      "           Short       0.51      0.12      0.19       347\n",
      "\n",
      "        accuracy                           0.07       713\n",
      "       macro avg       0.17      0.30      0.07       713\n",
      "    weighted avg       0.25      0.07      0.09       713\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Léo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Léo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Léo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Faz previsões de probabilidade\n",
    "y_pred_probs = rf.predict_proba(X_test)\n",
    "\n",
    "# Identifica a classe com maior probabilidade\n",
    "y_pred_indices = np.argmax(y_pred_probs, axis=1)\n",
    "\n",
    "# Mapeia os índices para as classes de interesse\n",
    "class_mapping = {0: 0, 1: 1, 2: -1}  # ajuste conforme necessário para sua classificação\n",
    "y_pred = np.vectorize(class_mapping.get)(y_pred_indices)\n",
    "\n",
    "# Avalia o modelo\n",
    "print(classification_report(y_test, y_pred, target_names=[\"Desfazer Posição\", \"Compra\", \"Short\"]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
