{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from indicadores import *\n",
    "import labeling as lb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Juntando os dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\pedro\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\ta\\trend.py:1030: FutureWarning: Series.__setitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To set a value by position, use `ser.iloc[pos] = value`\n",
      "  self._psar[i] = high2\n"
     ]
    }
   ],
   "source": [
    "# Calculando os indicadores e normalizando-os\n",
    "olhc = tsla_data\n",
    "data = agg_indicators(olhc)\n",
    "data = normalize_indicators(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertendo para numpy arrays, caso ainda não estejam\n",
    "X = np.array(data)  \n",
    "y = np.array(lb.labelData(olhc, 0.1)).ravel()\n",
    "\n",
    "# Divide os dados em conjuntos de treinamento e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fazendo a Rede Neural"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlp(data, hidden_layers=(100, 100, 100), activation='logistic', \n",
    "        solver='adam', max_iter=500, random_state=42):\n",
    "    \"\"\"\n",
    "    Treina um modelo de rede neural MLP e retorna as previsões e o relatório de classificação.\n",
    "\n",
    "    Parâmetros:\n",
    "    - data: DataFrame contendo os dados de entrada.\n",
    "    - hidden_layers: Tupla com o tamanho das camadas ocultas.\n",
    "    - activation: Função de ativação a ser usada.\n",
    "    - solver: Algoritmo de otimização a ser usado.\n",
    "    - max_iter: Número máximo de iterações.\n",
    "    - random_state: Semente para a geração de números aleatórios.\n",
    "\n",
    "    Retorna:\n",
    "    - y_pred_mlp: Previsões das classes no conjunto de teste.\n",
    "    - report: Relatório de classificação.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Agregando os indicadores\n",
    "    indicators_df = agg_indicators(data)\n",
    "\n",
    "    # Normalizando os indicadores\n",
    "    normalized_data = normalize_indicators(indicators_df)\n",
    "\n",
    "    # Separando as variáveis X e Y\n",
    "    X = normalized_data\n",
    "    y = label_tsla_data\n",
    "\n",
    "    # Dividinfo os dados em conjuntos de treinamento e teste\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=random_state)\n",
    "\n",
    "    # Definindo a rede neural com múltiplas camadas\n",
    "    mlp = MLPClassifier(hidden_layer_sizes=hidden_layers, activation=activation,\n",
    "                        solver=solver, max_iter=max_iter, random_state=random_state)\n",
    "\n",
    "    # Treina a rede neural\n",
    "    mlp.fit(X_train, y_train)\n",
    "\n",
    "    # Faz previsões de classe\n",
    "    y_pred_mlp = mlp.predict(X_test)\n",
    "\n",
    "    # Exibe o relatório de classificação para o MLP\n",
    "    report = classification_report(y_test, y_pred_mlp)\n",
    "    print(report)\n",
    "\n",
    "    return y_pred_mlp, report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fazendo o Modelo Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_forest(data, target_column, n_estimators=100, max_depth=None, random_state=42):\n",
    "    \"\"\"\n",
    "    Treina um modelo de Random Forest e retorna as previsões e o relatório de classificação.\n",
    "\n",
    "    Parâmetros:\n",
    "    - data: DataFrame com as features e a variável alvo.\n",
    "    - target_column: Nome da coluna alvo no DataFrame.\n",
    "    - n_estimators: Número de árvores na floresta.\n",
    "    - max_depth: Profundidade máxima das árvores (None para ilimitado).\n",
    "    - random_state: Semente para a geração de números aleatórios.\n",
    "\n",
    "    Retorna:\n",
    "    - y_pred_rf: Previsões das classes no conjunto de teste.\n",
    "    - report: Relatório de classificação.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Agregando os indicadores\n",
    "    indicators_df = agg_indicators(data)\n",
    "\n",
    "    # Normalizando os indicadores\n",
    "    normalized_data = normalize_indicators(indicators_df)\n",
    "\n",
    "    # Separando as variáveis X e Y\n",
    "    X = normalized_data\n",
    "    y = label_tsla_data\n",
    "\n",
    "    # Dividindo os dados em conjuntos de treinamento e teste\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=random_state)\n",
    "\n",
    "    # Definindo o modelo Random Forest\n",
    "    rf = RandomForestClassifier(n_estimators=n_estimators, max_depth=max_depth, \n",
    "                                 random_state=random_state)\n",
    "\n",
    "    # Treina o modelo Random Forest\n",
    "    rf.fit(X_train, y_train)\n",
    "\n",
    "    # Faz previsões de classe\n",
    "    y_pred_rf = rf.predict(X_test)\n",
    "\n",
    "    # Exibe o relatório de classificação para o Random Forest\n",
    "    report = classification_report(y_test, y_pred_rf)\n",
    "    print(report)\n",
    "\n",
    "    return y_pred_rf, report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fazendo o Modelo Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_boosting(data, target_column, random_state=42):\n",
    "    \"\"\"\n",
    "    Treina um modelo de Gradient Boosting e retorna as previsões e o relatório de classificação.\n",
    "\n",
    "    Parâmetros:\n",
    "    - data: DataFrame com as features e a variável alvo.\n",
    "    - target_column: Nome da coluna alvo no DataFrame.\n",
    "    - random_state: Semente para a geração de números aleatórios.\n",
    "\n",
    "    Retorna:\n",
    "    - y_pred_gb: Previsões das classes no conjunto de teste.\n",
    "    - report: Relatório de classificação.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Agregando os indicadores\n",
    "    indicators_df = agg_indicators(data)\n",
    "\n",
    "    # Normalizando os indicadores\n",
    "    normalized_data = normalize_indicators(indicators_df)\n",
    "\n",
    "    # Separando as variáveis X e Y\n",
    "    X = normalized_data\n",
    "    y = label_tsla_data\n",
    "\n",
    "    # Dividindo os dados em conjuntos de treinamento e teste\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=random_state)\n",
    "\n",
    "    # Definindo o modelo Gradient Boosting\n",
    "    gb_model = GradientBoostingClassifier(random_state=random_state)\n",
    "\n",
    "    # Treina o modelo Gradient Boosting\n",
    "    gb_model.fit(X_train, y_train)\n",
    "\n",
    "    # Faz previsões de classe\n",
    "    y_pred_gb = gb_model.predict(X_test)\n",
    "\n",
    "    # Exibe o relatório de classificação para o Gradient Boosting\n",
    "    report = classification_report(y_test, y_pred_gb)\n",
    "    print(report)\n",
    "\n",
    "    return y_pred_gb, report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_pred_probs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43my_pred_probs\u001b[49m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'y_pred_probs' is not defined"
     ]
    }
   ],
   "source": [
    "print(y_pred_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  precision    recall  f1-score   support\n",
      "\n",
      "Desfazer Posição       0.01      0.78      0.02         9\n",
      "          Compra       0.00      0.00      0.00       357\n",
      "           Short       0.51      0.12      0.19       347\n",
      "\n",
      "        accuracy                           0.07       713\n",
      "       macro avg       0.17      0.30      0.07       713\n",
      "    weighted avg       0.25      0.07      0.09       713\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Léo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Léo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Léo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Faz previsões de probabilidade\n",
    "y_pred_probs = rf.predict_proba(X_test)\n",
    "\n",
    "# Identifica a classe com maior probabilidade\n",
    "y_pred_indices = np.argmax(y_pred_probs, axis=1)\n",
    "\n",
    "# Mapeia os índices para as classes de interesse\n",
    "class_mapping = {0: 0, 1: 1, 2: -1}  # ajuste conforme necessário para sua classificação\n",
    "y_pred = np.vectorize(class_mapping.get)(y_pred_indices)\n",
    "\n",
    "# Avalia o modelo\n",
    "print(classification_report(y_test, y_pred, target_names=[\"Desfazer Posição\", \"Compra\", \"Short\"]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
